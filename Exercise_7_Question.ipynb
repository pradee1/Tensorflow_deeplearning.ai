{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradee1/Tensorflow_deeplearning.ai/blob/master/Exercise_7_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "09f76071-b6cd-468b-ef91-12a7ee24b4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150,150,3),\n",
        "                               include_top = False,\n",
        "                               weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-25 20:01:52--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.194.128, 2404:6800:4003:c04::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  87.7MB/s    in 1.0s    \n",
            "\n",
            "2019-06-25 20:01:54 (87.7 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0625 20:01:54.647411 139975015147392 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "e73fda65-fe1c-48e6-bef2-43c8c21496dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "0cb7042e-c286-438c-fd43-5e0ff3bf1dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation = 'relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation = 'sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0625 20:02:14.330532 139975015147392 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "342cbefa-2fb5-4566-97eb-4fbc2f7adaef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-25 20:02:17--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.128, 2404:6800:4003:c02::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  89.5MB/s    in 1.6s    \n",
            "\n",
            "2019-06-25 20:02:19 (89.5 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-06-25 20:02:20--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.130.128, 2404:6800:4003:c04::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.130.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-06-25 20:02:21 (181 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAciKv-o6OeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "da2c9f70-1a01-47ab-a424-b412906af12a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "train_horses_dir = os.path.join(train_dir, 'horses')\n",
        "train_humans_dir = os.path.join(train_dir, 'humans')\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses')\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "6d6f22ee-83de-4e5f-8fe4-7edb76a4c897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   zoom_range  = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size = (150,150),\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    batch_size = 20\n",
        "                                                   )     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                    target_size = (150,150),\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    batch_size = 20\n",
        "                                                   )\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "555fd472-d6ca-4fd3-b951-20b2f34d6d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data = validation_generator,\n",
        "                              verbose = 1,\n",
        "                              steps_per_epoch  =100,\n",
        "                              validation_steps = 50,\n",
        "                              epochs = 100,\n",
        "                              callbacks = [callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.2067 - acc: 0.9210 - val_loss: 0.0069 - val_acc: 0.9960\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 25s 245ms/step - loss: 0.0525 - acc: 0.9838 - val_loss: 0.1852 - val_acc: 0.9636\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 24s 240ms/step - loss: 0.0394 - acc: 0.9858 - val_loss: 0.0054 - val_acc: 0.9960\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 24s 236ms/step - loss: 0.0343 - acc: 0.9889 - val_loss: 0.0213 - val_acc: 0.9929\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.0473 - acc: 0.9828 - val_loss: 0.0527 - val_acc: 0.9889\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0497 - acc: 0.9878 - val_loss: 0.2062 - val_acc: 0.9696\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 24s 235ms/step - loss: 0.0323 - acc: 0.9904 - val_loss: 0.0384 - val_acc: 0.9939\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.0277 - acc: 0.9894 - val_loss: 0.2532 - val_acc: 0.9605\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0366 - acc: 0.9889 - val_loss: 0.4909 - val_acc: 0.9474\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0176 - acc: 0.9924 - val_loss: 0.4412 - val_acc: 0.9494\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 23s 231ms/step - loss: 0.0266 - acc: 0.9924 - val_loss: 0.2275 - val_acc: 0.9798\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0145 - acc: 0.9949 - val_loss: 0.3894 - val_acc: 0.9524\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0248 - acc: 0.9919 - val_loss: 0.7307 - val_acc: 0.9443\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0160 - acc: 0.9954 - val_loss: 0.6125 - val_acc: 0.9443\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 24s 239ms/step - loss: 0.0250 - acc: 0.9904 - val_loss: 0.5525 - val_acc: 0.9484\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 23s 233ms/step - loss: 0.0399 - acc: 0.9924 - val_loss: 0.3655 - val_acc: 0.9646\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0135 - acc: 0.9955 - val_loss: 0.2976 - val_acc: 0.9676\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0191 - acc: 0.9954 - val_loss: 0.6492 - val_acc: 0.9453\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0213 - acc: 0.9929 - val_loss: 0.8622 - val_acc: 0.9464\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0167 - acc: 0.9940 - val_loss: 0.4388 - val_acc: 0.9666\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.0273 - acc: 0.9914 - val_loss: 0.6641 - val_acc: 0.9453\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0054 - acc: 0.9980 - val_loss: 0.7054 - val_acc: 0.9484\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0189 - acc: 0.9950 - val_loss: 0.5353 - val_acc: 0.9656\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0129 - acc: 0.9965 - val_loss: 0.7400 - val_acc: 0.9504\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0203 - acc: 0.9934 - val_loss: 1.2547 - val_acc: 0.9352\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0130 - acc: 0.9960 - val_loss: 0.4842 - val_acc: 0.9676\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0053 - acc: 0.9980 - val_loss: 0.9386 - val_acc: 0.9494\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 24s 240ms/step - loss: 0.0089 - acc: 0.9969 - val_loss: 0.9752 - val_acc: 0.9504\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 23s 233ms/step - loss: 0.0167 - acc: 0.9950 - val_loss: 0.6331 - val_acc: 0.9565\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0558 - acc: 0.9909 - val_loss: 0.9217 - val_acc: 0.9484\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0152 - acc: 0.9975 - val_loss: 0.9847 - val_acc: 0.9494\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0140 - acc: 0.9969 - val_loss: 0.9332 - val_acc: 0.9514\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0180 - acc: 0.9970 - val_loss: 0.3781 - val_acc: 0.9717\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0183 - acc: 0.9954 - val_loss: 0.8899 - val_acc: 0.9504\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0092 - acc: 0.9980 - val_loss: 0.6711 - val_acc: 0.9575\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0147 - acc: 0.9954 - val_loss: 0.3971 - val_acc: 0.9646\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0070 - acc: 0.9975 - val_loss: 0.3998 - val_acc: 0.9717\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0188 - acc: 0.9955 - val_loss: 1.0609 - val_acc: 0.9433\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0173 - acc: 0.9975 - val_loss: 0.5609 - val_acc: 0.9575\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0074 - acc: 0.9965 - val_loss: 0.5874 - val_acc: 0.9575\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 24s 237ms/step - loss: 0.0097 - acc: 0.9975 - val_loss: 0.3643 - val_acc: 0.9717\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 23s 234ms/step - loss: 0.0263 - acc: 0.9959 - val_loss: 0.4802 - val_acc: 0.9646\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0282 - acc: 0.9950 - val_loss: 0.5818 - val_acc: 0.9615\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0123 - acc: 0.9970 - val_loss: 1.0713 - val_acc: 0.9433\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.6736 - val_acc: 0.9605\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0073 - acc: 0.9965 - val_loss: 0.2937 - val_acc: 0.9818\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0159 - acc: 0.9954 - val_loss: 0.3225 - val_acc: 0.9767\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0099 - acc: 0.9960 - val_loss: 0.2776 - val_acc: 0.9798\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0109 - acc: 0.9959 - val_loss: 0.6873 - val_acc: 0.9605\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0240 - acc: 0.9959 - val_loss: 1.3998 - val_acc: 0.9423\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0122 - acc: 0.9959 - val_loss: 0.7739 - val_acc: 0.9565\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0041 - acc: 0.9980 - val_loss: 0.8081 - val_acc: 0.9534\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0084 - acc: 0.9970 - val_loss: 0.9077 - val_acc: 0.9545\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 24s 239ms/step - loss: 0.0165 - acc: 0.9965 - val_loss: 0.7521 - val_acc: 0.9575\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 23s 232ms/step - loss: 0.0176 - acc: 0.9959 - val_loss: 0.3947 - val_acc: 0.9767\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.9646 - val_acc: 0.9494\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0151 - acc: 0.9969 - val_loss: 0.9182 - val_acc: 0.9494\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0170 - acc: 0.9960 - val_loss: 0.9729 - val_acc: 0.9484\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0119 - acc: 0.9975 - val_loss: 0.9875 - val_acc: 0.9484\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0152 - acc: 0.9955 - val_loss: 0.7915 - val_acc: 0.9565\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0107 - acc: 0.9975 - val_loss: 0.9826 - val_acc: 0.9534\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.9297 - val_acc: 0.9494\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 24s 236ms/step - loss: 0.0109 - acc: 0.9959 - val_loss: 0.6011 - val_acc: 0.9575\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0028 - acc: 0.9980 - val_loss: 0.8979 - val_acc: 0.9504\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.8809 - val_acc: 0.9494\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0075 - acc: 0.9975 - val_loss: 1.1578 - val_acc: 0.9474\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 24s 239ms/step - loss: 0.0167 - acc: 0.9985 - val_loss: 1.2244 - val_acc: 0.9453\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 23s 233ms/step - loss: 0.0244 - acc: 0.9954 - val_loss: 1.0759 - val_acc: 0.9494\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0098 - acc: 0.9980 - val_loss: 1.0338 - val_acc: 0.9484\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.8466 - val_acc: 0.9494\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0245 - acc: 0.9959 - val_loss: 1.2694 - val_acc: 0.9504\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0101 - acc: 0.9975 - val_loss: 1.4749 - val_acc: 0.9484\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0084 - acc: 0.9990 - val_loss: 1.1692 - val_acc: 0.9484\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0304 - acc: 0.9949 - val_loss: 1.3600 - val_acc: 0.9453\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0143 - acc: 0.9970 - val_loss: 1.4246 - val_acc: 0.9443\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0140 - acc: 0.9975 - val_loss: 1.0741 - val_acc: 0.9474\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0139 - acc: 0.9980 - val_loss: 0.7283 - val_acc: 0.9555\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0194 - acc: 0.9960 - val_loss: 0.8476 - val_acc: 0.9514\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0099 - acc: 0.9980 - val_loss: 1.2340 - val_acc: 0.9504\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 24s 238ms/step - loss: 0.0050 - acc: 0.9980 - val_loss: 1.2742 - val_acc: 0.9494\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 24s 235ms/step - loss: 0.0081 - acc: 0.9970 - val_loss: 1.4389 - val_acc: 0.9484\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0248 - acc: 0.9959 - val_loss: 1.9397 - val_acc: 0.9271\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0113 - acc: 0.9969 - val_loss: 1.3580 - val_acc: 0.9484\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0117 - acc: 0.9975 - val_loss: 2.0099 - val_acc: 0.9291\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0186 - acc: 0.9955 - val_loss: 1.8108 - val_acc: 0.9322\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0288 - acc: 0.9949 - val_loss: 1.8623 - val_acc: 0.9322\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0087 - acc: 0.9980 - val_loss: 1.0819 - val_acc: 0.9555\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0200 - acc: 0.9959 - val_loss: 1.6758 - val_acc: 0.9443\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0098 - acc: 0.9975 - val_loss: 1.6395 - val_acc: 0.9453\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0095 - acc: 0.9959 - val_loss: 1.9152 - val_acc: 0.9362\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0090 - acc: 0.9980 - val_loss: 1.3836 - val_acc: 0.9524\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0108 - acc: 0.9970 - val_loss: 2.3705 - val_acc: 0.9221\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 24s 237ms/step - loss: 0.0200 - acc: 0.9959 - val_loss: 2.2196 - val_acc: 0.9291\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 23s 233ms/step - loss: 0.0090 - acc: 0.9980 - val_loss: 1.6868 - val_acc: 0.9474\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0066 - acc: 0.9975 - val_loss: 2.1083 - val_acc: 0.9281\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0039 - acc: 0.9990 - val_loss: 1.8232 - val_acc: 0.9423\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0149 - acc: 0.9975 - val_loss: 1.1274 - val_acc: 0.9494\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0089 - acc: 0.9985 - val_loss: 1.3221 - val_acc: 0.9484\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0130 - acc: 0.9980 - val_loss: 1.7783 - val_acc: 0.9393\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0160 - acc: 0.9980 - val_loss: 1.3277 - val_acc: 0.9474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "6b90d0b4-035b-4a21-a9f0-03236c8c40ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.ylim([0.5,1.1])\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc3wQ5UIU2mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}